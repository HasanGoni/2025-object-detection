{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Module\n",
    "\n",
    "> Implementation of object detection models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN as TorchFasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from typing import Dict, List, Tuple, Union, Optional, Callable\n",
    "\n",
    "from objdetect.core import box_xyxy_to_cxcywh, box_cxcywh_to_xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backbone Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_backbone(name=\"resnet50\", pretrained=True, trainable_layers=3):\n",
    "    \"\"\"Create a backbone network with FPN.\n",
    "    \n",
    "    Args:\n",
    "        name: Backbone name (resnet18, resnet34, resnet50, resnet101)\n",
    "        pretrained: Whether to use pretrained weights\n",
    "        trainable_layers: Number of trainable layers (0 to 5)\n",
    "        \n",
    "    Returns:\n",
    "        Backbone network with FPN\n",
    "    \"\"\"\n",
    "    backbone = resnet_fpn_backbone(\n",
    "        backbone_name=name,\n",
    "        weights=\"DEFAULT\" if pretrained else None,\n",
    "        trainable_layers=trainable_layers\n",
    "    )\n",
    "    return backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FasterRCNN(nn.Module):\n",
    "    \"\"\"Faster R-CNN model for object detection.\n",
    "    \n",
    "    A wrapper around torchvision's Faster R-CNN with more convenient initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, backbone_name=\"resnet50\", pretrained_backbone=True, \n",
    "                 trainable_backbone_layers=3, min_size=800, max_size=1333,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes: Number of classes (including background)\n",
    "            backbone_name: Backbone name (resnet18, resnet34, resnet50, resnet101)\n",
    "            pretrained_backbone: Whether to use pretrained backbone\n",
    "            trainable_backbone_layers: Number of trainable backbone layers\n",
    "            min_size: Minimum size of the image to be rescaled\n",
    "            max_size: Maximum size of the image to be rescaled\n",
    "            **kwargs: Additional arguments for Faster R-CNN\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create backbone\n",
    "        backbone = create_backbone(\n",
    "            name=backbone_name,\n",
    "            pretrained=pretrained_backbone,\n",
    "            trainable_layers=trainable_backbone_layers\n",
    "        )\n",
    "        \n",
    "        # Define anchor generator\n",
    "        anchor_sizes = ((32,), (64,), (128,), (256,), (512,))\n",
    "        aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)\n",
    "        anchor_generator = AnchorGenerator(sizes=anchor_sizes, aspect_ratios=aspect_ratios)\n",
    "        \n",
    "        # Create Faster R-CNN model\n",
    "        self.model = TorchFasterRCNN(\n",
    "            backbone=backbone,\n",
    "            num_classes=num_classes,\n",
    "            rpn_anchor_generator=anchor_generator,\n",
    "            min_size=min_size,\n",
    "            max_size=max_size,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def forward(self, images, targets=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images: List[Tensor] or Tensor, input images\n",
    "            targets: Optional[List[Dict]], ground truth boxes and labels\n",
    "            \n",
    "        Returns:\n",
    "            In training, returns losses dict\n",
    "            In inference, returns List[Dict] with predictions\n",
    "        \"\"\"\n",
    "        # Convert single tensor to list for batch processing\n",
    "        if isinstance(images, torch.Tensor):\n",
    "            images = [img for img in images]\n",
    "            \n",
    "        return self.model(images, targets)\n",
    "    \n",
    "    def freeze_backbone(self):\n",
    "        \"\"\"Freeze backbone parameters.\"\"\"\n",
    "        for param in self.model.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def unfreeze_backbone(self):\n",
    "        \"\"\"Unfreeze backbone parameters.\"\"\"\n",
    "        for param in self.model.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    def predict(self, images, threshold=0.5):\n",
    "        \"\"\"Make predictions on images.\n",
    "        \n",
    "        Args:\n",
    "            images: List[PIL.Image] or PIL.Image or tensor\n",
    "            threshold: Confidence threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of prediction dictionaries\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            if not isinstance(images, list):\n",
    "                images = [images]\n",
    "                \n",
    "            # Convert PIL images to tensors if needed\n",
    "            processed_images = []\n",
    "            for img in images:\n",
    "                if not isinstance(img, torch.Tensor):\n",
    "                    img = torchvision.transforms.ToTensor()(img)\n",
    "                processed_images.append(img)\n",
    "                \n",
    "            predictions = self.model(processed_images)\n",
    "            \n",
    "            # Filter predictions by threshold\n",
    "            filtered_predictions = []\n",
    "            for pred in predictions:\n",
    "                scores = pred['scores']\n",
    "                keep = scores >= threshold\n",
    "                \n",
    "                filtered_pred = {\n",
    "                    'boxes': pred['boxes'][keep],\n",
    "                    'labels': pred['labels'][keep],\n",
    "                    'scores': scores[keep]\n",
    "                }\n",
    "                filtered_predictions.append(filtered_pred)\n",
    "                \n",
    "            return filtered_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Model (Stub for future implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class YOLO(nn.Module):\n",
    "    \"\"\"YOLO model for object detection.\n",
    "    \n",
    "    This is a placeholder for future implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, backbone_name=\"darknet\", **kwargs):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # Will be implemented in future versions\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        # Placeholder\n",
    "        return {\"loss\": torch.tensor(0.0, requires_grad=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factory Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_model(model_name=\"faster_rcnn\", num_classes=91, **kwargs):\n",
    "    \"\"\"Factory function to create object detection models.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Model type (faster_rcnn, yolo)\n",
    "        num_classes: Number of classes including background\n",
    "        **kwargs: Additional model-specific parameters\n",
    "        \n",
    "    Returns:\n",
    "        Object detection model\n",
    "    \"\"\"\n",
    "    model_name = model_name.lower()\n",
    "    \n",
    "    if model_name == \"faster_rcnn\":\n",
    "        return FasterRCNN(num_classes=num_classes, **kwargs)\n",
    "    elif model_name == \"yolo\":\n",
    "        return YOLO(num_classes=num_classes, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}