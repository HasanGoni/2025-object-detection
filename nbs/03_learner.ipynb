{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner Module\n",
    "\n",
    "> Training interface for object detection models in fastai style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Union, Optional, Callable\n",
    "from PIL import Image\n",
    "import torchmetrics\n",
    "\n",
    "from objdetect.core import plot_boxes\n",
    "from objdetect.data import ObjectDetectionDataset\n",
    "from objdetect.models import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Callback:\n",
    "    \"\"\"Base class for callbacks.\"\"\"\n",
    "    order = 0\n",
    "    \n",
    "    def before_fit(self, learner): pass\n",
    "    def after_fit(self, learner): pass\n",
    "    def before_epoch(self, learner): pass\n",
    "    def after_epoch(self, learner): pass\n",
    "    def before_batch(self, learner): pass\n",
    "    def after_batch(self, learner): pass\n",
    "    def before_backward(self, learner): pass\n",
    "    def after_backward(self, learner): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ProgressCallback(Callback):\n",
    "    \"\"\"Display training progress.\"\"\"\n",
    "    order = 0\n",
    "    \n",
    "    def before_fit(self, learner):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def after_batch(self, learner):\n",
    "        if learner.training:\n",
    "            # Only log every 10 batches to avoid flooding output\n",
    "            if learner.batch_idx % 10 == 0:\n",
    "                loss_str = \", \".join([f\"{k}: {v:.4f}\" for k, v in learner.loss_dict.items()])\n",
    "                print(f\"Epoch {learner.epoch+1}/{learner.n_epochs}, Batch {learner.batch_idx+1}/{len(learner.train_dl)}, {loss_str}\")\n",
    "                \n",
    "            # Save loss for plotting\n",
    "            self.train_losses.append(learner.loss.item())\n",
    "    \n",
    "    def after_epoch(self, learner):\n",
    "        # Save validation loss for plotting\n",
    "        if not learner.training and hasattr(learner, 'val_loss'):\n",
    "            self.val_losses.append(learner.val_loss)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        if not learner.training:\n",
    "            train_loss = sum(self.train_losses[-len(learner.train_dl):])/len(learner.train_dl)\n",
    "            print(f\"Epoch {learner.epoch+1}/{learner.n_epochs} - Train Loss: {train_loss:.4f}\")\n",
    "            \n",
    "            if hasattr(learner, 'val_loss'):\n",
    "                print(f\"Epoch {learner.epoch+1}/{learner.n_epochs} - Val Loss: {learner.val_loss:.4f}\")\n",
    "                \n",
    "    def after_fit(self, learner):\n",
    "        # Plot loss curves\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.train_losses, label='Train Loss')\n",
    "        \n",
    "        if self.val_losses:\n",
    "            # Plot validation loss points (one per epoch)\n",
    "            x_vals = np.linspace(0, len(self.train_losses)-1, len(self.val_losses))\n",
    "            plt.plot(x_vals, self.val_losses, 'ro-', label='Val Loss')\n",
    "            \n",
    "        plt.xlabel('Batch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OneCycleScheduler(Callback):\n",
    "    \"\"\"One cycle learning rate scheduler.\"\"\"\n",
    "    order = 1\n",
    "    \n",
    "    def __init__(self, max_lr, pct_start=0.3, div_factor=25., final_div_factor=1e4):\n",
    "        self.max_lr = max_lr\n",
    "        self.pct_start = pct_start\n",
    "        self.div_factor = div_factor\n",
    "        self.final_div_factor = final_div_factor\n",
    "        \n",
    "    def before_fit(self, learner):\n",
    "        self.n_steps = learner.n_epochs * len(learner.train_dl)\n",
    "        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            learner.optimizer,\n",
    "            max_lr=self.max_lr,\n",
    "            total_steps=self.n_steps,\n",
    "            pct_start=self.pct_start,\n",
    "            div_factor=self.div_factor,\n",
    "            final_div_factor=self.final_div_factor\n",
    "        )\n",
    "        \n",
    "    def after_batch(self, learner):\n",
    "        if learner.training:\n",
    "            self.scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SaveModelCallback(Callback):\n",
    "    \"\"\"Save model checkpoint.\"\"\"\n",
    "    order = 2\n",
    "    \n",
    "    def __init__(self, save_path='checkpoints', save_name='model', monitor='val_loss', mode='min'):\n",
    "        self.save_path = Path(save_path)\n",
    "        self.save_name = save_name\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.best_value = float('inf') if mode == 'min' else float('-inf')\n",
    "        \n",
    "    def before_fit(self, learner):\n",
    "        self.save_path.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "    def after_epoch(self, learner):\n",
    "        if not learner.training:\n",
    "            current_value = getattr(learner, self.monitor, None)\n",
    "            \n",
    "            if current_value is not None:\n",
    "                improved = (self.mode == 'min' and current_value < self.best_value) or \\\n",
    "                           (self.mode == 'max' and current_value > self.best_value)\n",
    "                           \n",
    "                if improved:\n",
    "                    self.best_value = current_value\n",
    "                    path = self.save_path / f\"{self.save_name}_best.pth\"\n",
    "                    torch.save(learner.model.state_dict(), path)\n",
    "                    print(f\"Saved model to {path} with {self.monitor}={current_value:.4f}\")\n",
    "                    \n",
    "            # Save last model\n",
    "            path = self.save_path / f\"{self.save_name}_last.pth\"\n",
    "            torch.save(learner.model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ObjectDetectionLearner:\n",
    "    \"\"\"Learner for training object detection models.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, model=None, batch_size=4, num_workers=2, \n",
    "                 callbacks=None, device=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset: ObjectDetectionDataset or tuple of (train_ds, val_ds)\n",
    "            model: Object detection model or model name\n",
    "            batch_size: Batch size for training\n",
    "            num_workers: Number of workers for data loading\n",
    "            callbacks: List of callbacks\n",
    "            device: Device to use (auto-detected if None)\n",
    "        \"\"\"\n",
    "        # Set device\n",
    "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Handle dataset\n",
    "        if isinstance(dataset, tuple):\n",
    "            self.train_ds, self.val_ds = dataset\n",
    "        else:\n",
    "            # If only one dataset is provided, use it for both train and val\n",
    "            self.train_ds = dataset\n",
    "            self.val_ds = dataset\n",
    "            \n",
    "        # Create data loaders\n",
    "        self.train_dl = DataLoader(\n",
    "            self.train_ds, batch_size=batch_size, shuffle=True,\n",
    "            num_workers=num_workers, collate_fn=self.train_ds.collate_fn\n",
    "        )\n",
    "        \n",
    "        self.val_dl = DataLoader(\n",
    "            self.val_ds, batch_size=batch_size, shuffle=False,\n",
    "            num_workers=num_workers, collate_fn=self.val_ds.collate_fn\n",
    "        ) if self.val_ds != self.train_ds else None\n",
    "        \n",
    "        # Handle model\n",
    "        if model is None:\n",
    "            # Create default model\n",
    "            self.model = create_model(num_classes=self.train_ds.num_classes)\n",
    "        elif isinstance(model, str):\n",
    "            # Create model from name\n",
    "            self.model = create_model(model, num_classes=self.train_ds.num_classes)\n",
    "        else:\n",
    "            # Use provided model\n",
    "            self.model = model\n",
    "            \n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        # Set up callbacks\n",
    "        self.callbacks = [ProgressCallback()] if callbacks is None else callbacks\n",
    "        # Sort callbacks by order\n",
    "        self.callbacks = sorted(self.callbacks, key=lambda x: x.order)\n",
    "        \n",
    "    def _prepare_batch(self, batch):\n",
    "        \"\"\"Prepare batch for training.\"\"\"\n",
    "        images, targets = batch\n",
    "        \n",
    "        # Move images to device\n",
    "        images = [img.to(self.device) for img in images]\n",
    "        \n",
    "        # Move targets to device\n",
    "        targets = [{k: v.to(self.device) if isinstance(v, torch.Tensor) else v \n",
    "                   for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        return images, targets\n",
    "    \n",
    "    def fit(self, n_epochs, lr=1e-4, optimizer=None):\n",
    "        \"\"\"Train the model.\n",
    "        \n",
    "        Args:\n",
    "            n_epochs: Number of epochs\n",
    "            lr: Learning rate\n",
    "            optimizer: Optimizer (default: Adam)\n",
    "        \"\"\"\n",
    "        self.n_epochs = n_epochs\n",
    "        \n",
    "        # Set up optimizer\n",
    "        self.optimizer = optimizer or torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        # Call before_fit for all callbacks\n",
    "        for cb in self.callbacks:\n",
    "            cb.before_fit(self)\n",
    "            \n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            self.epoch = epoch\n",
    "            \n",
    "            # Training phase\n",
    "            self.model.train()\n",
    "            self.training = True\n",
    "            \n",
    "            # Call before_epoch for all callbacks\n",
    "            for cb in self.callbacks:\n",
    "                cb.before_epoch(self)\n",
    "                \n",
    "            for batch_idx, batch in enumerate(self.train_dl):\n",
    "                self.batch_idx = batch_idx\n",
    "                self.batch = batch\n",
    "                \n",
    "                # Call before_batch for all callbacks\n",
    "                for cb in self.callbacks:\n",
    "                    cb.before_batch(self)\n",
    "                    \n",
    "                # Forward pass\n",
    "                images, targets = self._prepare_batch(batch)\n",
    "                loss_dict = self.model(images, targets)\n",
    "                \n",
    "                # Get total loss\n",
    "                self.loss_dict = {k: v.item() for k, v in loss_dict.items()}\n",
    "                self.loss = sum(loss for loss in loss_dict.values())\n",
    "                \n",
    "                # Backward pass\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # Call before_backward for all callbacks\n",
    "                for cb in self.callbacks:\n",
    "                    cb.before_backward(self)\n",
    "                    \n",
    "                self.loss.backward()\n",
    "                \n",
    "                # Call after_backward for all callbacks\n",
    "                for cb in self.callbacks:\n",
    "                    cb.after_backward(self)\n",
    "                    \n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # Call after_batch for all callbacks\n",
    "                for cb in self.callbacks:\n",
    "                    cb.after_batch(self)\n",
    "            \n",
    "            # Validation phase\n",
    "            if self.val_dl is not None:\n",
    "                self.model.eval()\n",
    "                self.training = False\n",
    "                val_losses = []\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for batch_idx, batch in enumerate(self.val_dl):\n",
    "                        self.batch_idx = batch_idx\n",
    "                        self.batch = batch\n",
    "                        \n",
    "                        # Call before_batch for all callbacks\n",
    "                        for cb in self.callbacks:\n",
    "                            cb.before_batch(self)\n",
    "                            \n",
    "                        # Forward pass\n",
    "                        images, targets = self._prepare_batch(batch)\n",
    "                        loss_dict = self.model(images, targets)\n",
    "                        \n",
    "                        # Get total loss\n",
    "                        loss = sum(loss for loss in loss_dict.values())\n",
    "                        val_losses.append(loss.item())\n",
    "                        \n",
    "                        # Call after_batch for all callbacks\n",
    "                        for cb in self.callbacks:\n",
    "                            cb.after_batch(self)\n",
    "                \n",
    "                self.val_loss = sum(val_losses) / len(val_losses)\n",
    "            \n",
    "            # Call after_epoch for all callbacks\n",
    "            for cb in self.callbacks:\n",
    "                cb.after_epoch(self)\n",
    "        \n",
    "        # Call after_fit for all callbacks\n",
    "        for cb in self.callbacks:\n",
    "            cb.after_fit(self)\n",
    "    \n",
    "    def fit_one_cycle(self, n_epochs, max_lr=1e-3):\n",
    "        \"\"\"Train with the 1cycle policy.\n",
    "        \n",
    "        Args:\n",
    "            n_epochs: Number of epochs\n",
    "            max_lr: Maximum learning rate\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=max_lr/25)\n",
    "        one_cycle = OneCycleScheduler(max_lr=max_lr)\n",
    "        \n",
    "        # Add OneCycleScheduler to callbacks if not already present\n",
    "        for cb in self.callbacks:\n",
    "            if isinstance(cb, OneCycleScheduler):\n",
    "                break\n",
    "        else:\n",
    "            self.callbacks.append(one_cycle)\n",
    "            self.callbacks = sorted(self.callbacks, key=lambda x: x.order)\n",
    "        \n",
    "        self.fit(n_epochs=n_epochs, optimizer=optimizer)\n",
    "        \n",
    "    def predict(self, img, threshold=0.5):\n",
    "        \"\"\"Make prediction on a single image.\n",
    "        \n",
    "        Args:\n",
    "            img: PIL.Image or file path or tensor\n",
    "            threshold: Confidence threshold\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with prediction results\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Load image if path is provided\n",
    "        if isinstance(img, (str, Path)):\n",
    "            img = Image.open(img).convert('RGB')\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            if hasattr(self.model, 'predict'):\n",
    "                pred = self.model.predict(img, threshold=threshold)[0]\n",
    "            else:\n",
    "                # For models without a predict method\n",
    "                if not isinstance(img, torch.Tensor):\n",
    "                    img = torchvision.transforms.ToTensor()(img)\n",
    "                img = img.to(self.device).unsqueeze(0)\n",
    "                pred = self.model(img)[0]\n",
    "                \n",
    "                # Filter by threshold\n",
    "                keep = pred['scores'] >= threshold\n",
    "                pred = {k: v[keep] for k, v in pred.items()}\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def show_results(self, img, pred=None, figsize=(10, 10)):\n",
    "        \"\"\"Show prediction results.\n",
    "        \n",
    "        Args:\n",
    "            img: PIL.Image or file path or tensor\n",
    "            pred: Prediction dictionary (if None, predict will be called)\n",
    "            figsize: Figure size\n",
    "            \n",
    "        Returns:\n",
    "            Matplotlib figure\n",
    "        \"\"\"\n",
    "        # Load image if path is provided\n",
    "        if isinstance(img, (str, Path)):\n",
    "            img_path = img\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "        # Make prediction if not provided\n",
    "        if pred is None:\n",
    "            pred = self.predict(img)\n",
    "            \n",
    "        boxes = pred['boxes'].cpu() if 'boxes' in pred else None\n",
    "        labels = pred['labels'].cpu() if 'labels' in pred else None\n",
    "        scores = pred['scores'].cpu() if 'scores' in pred else None\n",
    "        \n",
    "        class_names = self.train_ds.class_names if hasattr(self.train_ds, 'class_names') else None\n",
    "        \n",
    "        return plot_boxes(img, boxes, labels, scores, class_names, figsize=figsize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}